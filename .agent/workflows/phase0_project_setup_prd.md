---
description: # Phase 0: Project Setup & Architecture | ## Objective Establish the project foundation including development environment, architecture decisions, version control setup, and initial project scaffolding. This phase ensures all developers have a consis
---

## Tech Stack
- **Version Control**: Git + GitHub
- **Container Platform**: Docker + Docker Compose
- **Python Version**: 3.11+
- **Node Version**: 20 LTS (for dashboard)
- **IDE**: VS Code (recommended) with extensions
- **Code Formatting**: Black (Python), Prettier (TypeScript)
- **Linting**: Ruff (Python), ESLint (TypeScript)
- **Pre-commit Hooks**: pre-commit framework
- **API Documentation**: OpenAPI/Swagger (auto-generated by FastAPI)

## User Flow
1. Developer clones repository from GitHub
2. Developer runs setup script: `./scripts/setup.sh`
3. Script installs dependencies, sets up databases, creates .env files
4. Developer runs `docker-compose up` to start all services
5. Developer accesses API documentation at `http://localhost:8000/docs`
6. Developer accesses dashboard at `http://localhost:5173`
7. Developer makes code changes with IDE
8. Pre-commit hooks run linting and formatting automatically
9. Developer commits and pushes to feature branch
10. CI/CD pipeline runs tests and reports status

## Technical Constraints
- **Local Development**: All services must run on localhost without cloud dependencies
- **Port Allocation**: Standard ports must not conflict (8000=API, 5173=Dashboard, 5432=Postgres, 6379=Redis)
- **Environment Isolation**: Each developer must have isolated database and Redis instance
- **Reproducibility**: Setup process must be automated and documented
- **No External APIs**: Phase 0 uses mock data for LLM and embedding services

## Architecture Decisions

### System Architecture
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        CLIENT LAYER                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ  Web Widget  ‚îÇ  ‚îÇ  Mobile App  ‚îÇ  ‚îÇ Teams/Slack  ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      INGRESS LAYER                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ           API Gateway (Nginx/Kong)                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   Rate Limiting, SSL, Load Balancing, Routing        ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ           Auth Service (OAuth 2.0 / OIDC)            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   Tenant Identification, JWT Verification            ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    APPLICATION LAYER                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ
‚îÇ  ‚îÇ Chat Orchestrator‚îÇ  ‚îÇ Tenant Config     ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ - Session Mgmt   ‚îÇ  ‚îÇ - Bot Settings    ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ - Intent Router  ‚îÇ  ‚îÇ - Custom Prompts  ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ - Context Handle ‚îÇ  ‚îÇ - Rate Limits     ‚îÇ               ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ
‚îÇ  ‚îÇ Message Queue    ‚îÇ  ‚îÇ Observability     ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ - Kafka/Redis    ‚îÇ  ‚îÇ - Logging         ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ - Async Process  ‚îÇ  ‚îÇ - Metrics         ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ - Event Stream   ‚îÇ  ‚îÇ - Tracing         ‚îÇ               ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                       AI/ML LAYER                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ
‚îÇ  ‚îÇ  LLM Gateway     ‚îÇ  ‚îÇ   RAG Engine      ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ - Model Router   ‚îÇ  ‚îÇ - Vector Search   ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ - Prompt Engine  ‚îÇ  ‚îÇ - Context Inject  ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ - Token Mgmt     ‚îÇ  ‚îÇ - Knowledge Ret   ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ - Fallback Logic ‚îÇ  ‚îÇ                   ‚îÇ               ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                       ‚îÇ
‚îÇ  ‚îÇ  NLU Service     ‚îÇ                                       ‚îÇ
‚îÇ  ‚îÇ - Intent Classify‚îÇ                                       ‚îÇ
‚îÇ  ‚îÇ - Entity Extract ‚îÇ                                       ‚îÇ
‚îÇ  ‚îÇ - Sentiment Anal ‚îÇ                                       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        DATA LAYER                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Conversation DB‚îÇ  ‚îÇ  Vector Store  ‚îÇ  ‚îÇ Knowledge Base‚îÇ ‚îÇ
‚îÇ  ‚îÇ - PostgreSQL   ‚îÇ  ‚îÇ - Pinecone     ‚îÇ  ‚îÇ - Blob Storage‚îÇ ‚îÇ
‚îÇ  ‚îÇ - Chat History ‚îÇ  ‚îÇ - Embeddings   ‚îÇ  ‚îÇ - Tenant Docs ‚îÇ ‚îÇ
‚îÇ  ‚îÇ - Session State‚îÇ  ‚îÇ - Semantic Idx ‚îÇ  ‚îÇ (PDF/CSV)     ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                         ‚îÇ
‚îÇ  ‚îÇ  Cache Layer   ‚îÇ                                         ‚îÇ
‚îÇ  ‚îÇ - Redis        ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇ - Session Cache‚îÇ    ‚îÇ      ISOLATION BOX       ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ - Response     ‚îÇ    ‚îÇ  Row-Level Security      ‚îÇ        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ  Namespace Partitioning  ‚îÇ        ‚îÇ
‚îÇ                        ‚îÇ  Encryption at Rest      ‚îÇ        ‚îÇ
‚îÇ                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Key Architecture Principles

1. **Multi-Tenancy Pattern**: Schema-per-tenant isolation
   - Tenant ID required in all database queries (enforced at ORM level)
   - Vector embeddings namespaced by tenant_id
   - Redis cache keys prefixed with tenant_id

2. **Event-Driven Architecture**: 
   - Webhooks ‚Üí Message Queue ‚Üí Async Workers ‚Üí Response
   - Decouples ingress from processing for scalability

3. **Microservices Readiness** (Phase 6+):
   - Monolith initially, but designed for future service extraction
   - Clear service boundaries (Chat, RAG, Auth, Analytics)

4. **Data Flow** (for each message):
   ```
   Customer Message ‚Üí Webhook ‚Üí Identify Tenant ‚Üí Queue Message
   ‚Üí Worker Picks Up ‚Üí Retrieve Session Context ‚Üí RAG Query
   ‚Üí LLM Generate ‚Üí Send Response ‚Üí Store Message ‚Üí Update Metrics
   ```

## Project Structure
```
wafaa-platform/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ ARCHITECTURE.md
‚îú‚îÄ‚îÄ CONTRIBUTING.md
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ .pre-commit-config.yaml
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ docker-compose.prod.yml
‚îÇ
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ requirements-dev.txt
‚îÇ   ‚îú‚îÄ‚îÄ alembic.ini
‚îÇ   ‚îú‚îÄ‚îÄ pyproject.toml
‚îÇ   ‚îú‚îÄ‚îÄ .env.example
‚îÇ   ‚îú‚îÄ‚îÄ alembic/
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ scripts/
‚îÇ       ‚îú‚îÄ‚îÄ seed_data.py
‚îÇ       ‚îî‚îÄ‚îÄ test_setup.py
‚îÇ
‚îú‚îÄ‚îÄ dashboard/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îú‚îÄ‚îÄ tsconfig.json
‚îÇ   ‚îú‚îÄ‚îÄ vite.config.ts
‚îÇ   ‚îú‚îÄ‚îÄ .env.example
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ public/
‚îÇ   ‚îî‚îÄ‚îÄ tests/
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ openapi.yaml
‚îÇ   ‚îú‚îÄ‚îÄ architecture/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ system-diagram.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data-flow.png
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rag-pipeline.png
‚îÇ   ‚îú‚îÄ‚îÄ guides/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ setup.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ development.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ deployment.md
‚îÇ   ‚îî‚îÄ‚îÄ decisions/
‚îÇ       ‚îú‚îÄ‚îÄ 001-multi-tenancy-approach.md
‚îÇ       ‚îú‚îÄ‚îÄ 002-vector-database-choice.md
‚îÇ       ‚îî‚îÄ‚îÄ 003-message-queue-selection.md
‚îÇ
‚îú‚îÄ‚îÄ infrastructure/
‚îÇ   ‚îú‚îÄ‚îÄ nginx/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ nginx.conf
‚îÇ   ‚îú‚îÄ‚îÄ postgres/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ init.sql
‚îÇ   ‚îî‚îÄ‚îÄ prometheus/
‚îÇ       ‚îî‚îÄ‚îÄ prometheus.yml
‚îÇ
‚îî‚îÄ‚îÄ scripts/
    ‚îú‚îÄ‚îÄ setup.sh
    ‚îú‚îÄ‚îÄ backup.sh
    ‚îú‚îÄ‚îÄ migrate.sh
    ‚îî‚îÄ‚îÄ deploy.sh
```

## Docker Compose Configuration

### docker-compose.yml
```yaml
version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    container_name: wafaa-postgres
    environment:
      POSTGRES_DB: wafaa_db
      POSTGRES_USER: wafaa_user
      POSTGRES_PASSWORD: dev_password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./infrastructure/postgres/init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U wafaa_user"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: wafaa-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: wafaa-backend
    environment:
      - DATABASE_URL=postgresql://wafaa_user:dev_password@postgres:5432/wafaa_db
      - REDIS_URL=redis://redis:6379/0
      - SECRET_KEY=dev-secret-key-change-in-production
      - DEBUG=true
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app
      - /app/.venv  # Prevent overwriting venv
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

  celery-worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: wafaa-celery
    environment:
      - DATABASE_URL=postgresql://wafaa_user:dev_password@postgres:5432/wafaa_db
      - REDIS_URL=redis://redis:6379/0
    volumes:
      - ./backend:/app
    depends_on:
      - postgres
      - redis
    command: celery -A app.workers.celery_app worker --loglevel=info

  dashboard:
    build:
      context: ./dashboard
      dockerfile: Dockerfile
    container_name: wafaa-dashboard
    environment:
      - VITE_API_BASE_URL=http://localhost:8000/api/v1
    ports:
      - "5173:5173"
    volumes:
      - ./dashboard:/app
      - /app/node_modules
    command: npm run dev -- --host

volumes:
  postgres_data:
  redis_data:
```

## Setup Script

### scripts/setup.sh
```bash
#!/bin/bash

set -e  # Exit on error

echo "üöÄ Wafaa Platform Setup"
echo "======================="

# Check prerequisites
command -v docker >/dev/null 2>&1 || { echo "‚ùå Docker not found. Please install Docker."; exit 1; }
command -v docker-compose >/dev/null 2>&1 || { echo "‚ùå Docker Compose not found."; exit 1; }
command -v python3 >/dev/null 2>&1 || { echo "‚ùå Python 3 not found."; exit 1; }
command -v node >/dev/null 2>&1 || { echo "‚ùå Node.js not found."; exit 1; }

echo "‚úÖ Prerequisites check passed"

# Create environment files
echo "üìù Creating environment files..."

if [ ! -f backend/.env ]; then
    cp backend/.env.example backend/.env
    echo "‚úÖ Created backend/.env (please update with your settings)"
fi

if [ ! -f dashboard/.env ]; then
    cp dashboard/.env.example dashboard/.env
    echo "‚úÖ Created dashboard/.env"
fi

# Install pre-commit hooks
echo "üîß Installing pre-commit hooks..."
pip install pre-commit
pre-commit install

# Start services
echo "üê≥ Starting Docker services..."
docker-compose up -d postgres redis

# Wait for database
echo "‚è≥ Waiting for database to be ready..."
sleep 5

# Run migrations
echo "üóÑÔ∏è  Running database migrations..."
docker-compose run --rm backend alembic upgrade head

# Seed data
echo "üå± Seeding initial data..."
docker-compose run --rm backend python scripts/seed_data.py

# Install backend dependencies
echo "üì¶ Installing backend dependencies..."
cd backend
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements-dev.txt
cd ..

# Install dashboard dependencies
echo "üì¶ Installing dashboard dependencies..."
cd dashboard
npm install
cd ..

# Start all services
echo "üöÄ Starting all services..."
docker-compose up -d

echo ""
echo "‚úÖ Setup complete!"
echo ""
echo "Services available at:"
echo "  - API: http://localhost:8000"
echo "  - API Docs: http://localhost:8000/docs"
echo "  - Dashboard: http://localhost:5173"
echo ""
echo "Test credentials:"
echo "  Email: admin@example.com"
echo "  Password: admin123"
echo ""
echo "To view logs: docker-compose logs -f"
echo "To stop services: docker-compose down"
```

## Pre-commit Configuration

### .pre-commit-config.yaml
```yaml
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files
        args: ['--maxkb=1000']
      - id: check-json
      - id: check-merge-conflict

  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.1.8
    hooks:
      - id: ruff
        args: [--fix, --exit-non-zero-on-fix]
      - id: ruff-format

  - repo: https://github.com/pre-commit/mirrors-prettier
    rev: v3.1.0
    hooks:
      - id: prettier
        files: \.(js|jsx|ts|tsx|css|md|json)$
```

## Development Workflow

### Git Branching Strategy
```
main (production)
  ‚Üì
develop (staging)
  ‚Üì
feature/[phase]-[feature-name]
  examples:
    - feature/phase1-auth-system
    - feature/phase2-rag-engine
    - feature/phase3-whatsapp-integration
```

### Commit Message Convention
```
<type>(<scope>): <subject>

Types: feat, fix, docs, style, refactor, test, chore
Scopes: auth, rag, channels, dashboard, api, db

Examples:
feat(auth): implement JWT refresh token logic
fix(rag): correct vector search tenant filtering
docs(api): update webhook endpoint documentation
```

## Environment Variables

### backend/.env.example
```bash
# Application
APP_NAME=Wafaa AI Concierge
APP_VERSION=1.0.0
DEBUG=true
LOG_LEVEL=INFO

# Database
DATABASE_URL=postgresql://wafaa_user:dev_password@localhost:5432/wafaa_db
DB_POOL_SIZE=20
DB_MAX_OVERFLOW=10

# Redis
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# Security
SECRET_KEY=generate-with-openssl-rand-hex-32
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
REFRESH_TOKEN_EXPIRE_DAYS=7

# CORS
CORS_ORIGINS=["http://localhost:5173"]

# File Storage
UPLOAD_DIR=/data/uploads
MAX_FILE_SIZE_MB=10
ALLOWED_FILE_TYPES=pdf,docx,txt,csv

# AI/ML (Mock for Phase 0)
LLM_PROVIDER=mock
EMBEDDING_PROVIDER=mock
VECTOR_DB_PROVIDER=mock

# Monitoring (Disabled for Phase 0)
SENTRY_DSN=
PROMETHEUS_ENABLED=false
```

### dashboard/.env.example
```bash
VITE_API_BASE_URL=http://localhost:8000/api/v1
VITE_WS_URL=ws://localhost:8000
VITE_APP_NAME=Wafaa Admin Dashboard
VITE_ENABLE_DEV_TOOLS=true
```

## Definition of Done

### Code Requirements
- [ ] Git repository initialized with proper .gitignore
- [ ] Docker Compose configuration runs all services
- [ ] Setup script executes without errors
- [ ] Pre-commit hooks installed and working
- [ ] Backend FastAPI app starts on port 8000
- [ ] Dashboard React app starts on port 5173
- [ ] PostgreSQL accessible on port 5432
- [ ] Redis accessible on port 6379
- [ ] All environment variables documented

### Testing Requirements
- [ ] Database migrations run successfully
- [ ] Seed data creates test tenant accounts
- [ ] API health endpoint returns 200
- [ ] API docs accessible at /docs
- [ ] Dashboard loads without errors
- [ ] Pre-commit hooks block commits with linting errors

### Functional Requirements
- [ ] Developer can clone repo and run setup in < 10 minutes
- [ ] All services start with `docker-compose up`
- [ ] Services persist data across restarts
- [ ] Logs viewable via `docker-compose logs`
- [ ] Services stop cleanly with `docker-compose down`
- [ ] Backend hot-reloads on code changes
- [ ] Dashboard hot-reloads on code changes

### Documentation Requirements
- [ ] README.md explains project purpose and setup
- [ ] ARCHITECTURE.md documents system design
- [ ] CONTRIBUTING.md explains development workflow
- [ ] API documented in OpenAPI/Swagger
- [ ] Architecture diagrams created (system, data flow)
- [ ] ADRs (Architecture Decision Records) started
- [ ] Setup troubleshooting guide created

### Security Requirements
- [ ] No secrets committed to Git
- [ ] .env.example provided with placeholder values
- [ ] Default passwords documented as dev-only
- [ ] Database exposed only on localhost
- [ ] Redis not publicly accessible

## Success Metrics
- New developer onboarded in < 30 minutes
- Zero setup failures in CI/CD environment
- All services start within 60 seconds
- Pre-commit hooks catch 100% of linting issues
- Documentation completeness score > 90%

## Architecture Decision Records

### ADR-001: Multi-Tenancy Approach
**Status**: Accepted  
**Context**: Need to isolate tenant data for security and compliance  
**Decision**: Use tenant_id column in all tables with row-level filtering  
**Consequences**: Simpler than separate schemas, scales to thousands of tenants

### ADR-002: Vector Database Choice
**Status**: Proposed  
**Context**: Need fast semantic search with tenant isolation  
**Options**: Pinecone (hosted), Weaviate (self-hosted), Qdrant  
**Decision**: Start with Pinecone for simplicity, evaluate Weaviate for self-hosting  
**Consequences**: Vendor dependency, but faster time-to-market

### ADR-003: Message Queue Selection
**Status**: Accepted  
**Context**: Need reliable async processing with replay capability  
**Decision**: Redis Streams for Phase 1-4, migrate to Kafka at scale  
**Consequences**: Simpler setup initially, clear migration path for high volume

## Next Steps
After Phase 0 completion, proceed to Phase 1 (Foundation & Core Infrastructure) to implement:
- Database models and migrations
- Authentication system
- Tenant management APIs
- Basic CRUD operations