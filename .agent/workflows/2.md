---
description: Debug and Production
---

# Wafaa Workflows 2: Debug & Production

## Debugging Multi-Tenant Issues

### Issue: Tenant Context Not Set
```python
# Add logging to middleware
@app.middleware("http")
async def tenant_middleware(request: Request, call_next):
    logger.info(f"Path: {request.url.path}")
    tenant_id = extract_tenant_from_request(request)
    logger.info(f"Tenant: {tenant_id}")
    
    if tenant_id:
        TenantContext.set_tenant(tenant_id)
    
    response = await call_next(request)
    TenantContext.clear()
    return response
```

### Issue: Data Leakage
```python
# Add assertions
async def get_documents(client_id: UUID):
    current = TenantContext.get_tenant()
    assert current == client_id, f"Mismatch: {current} != {client_id}"
    
    return await db.query(Doc).filter(Doc.client_id == client_id).all()

# Use safe query wrapper
class TenantQuery:
    @staticmethod
    async def query(model):
        tenant_id = TenantContext.get_tenant()
        if not tenant_id: raise ValueError("No tenant context")
        return db.query(model).filter(model.client_id == tenant_id)

# Usage
docs = await TenantQuery.query(KnowledgeDocument).all()
```

### Debug Logging
```python
import logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

# In functions
logger.debug(f"Processing for tenant: {TenantContext.get_tenant()}")
logger.info(f"Query took {duration:.2f}s")
```

### Inspect RAG Results
```python
results = await rag.retrieve_context(query, client_id)
for i, doc in enumerate(results):
    print(f"Result {i+1}: Score={doc.score}")
    print(f"  Text: {doc.text[:100]}...")
    print(f"  Metadata: {doc.metadata}")
```

### Test Webhooks Locally
```bash
# Use ngrok
ngrok http 8000
# Update webhook URL to: https://abc123.ngrok.io/webhook/whatsapp/slug
```

## Database Debugging

### Find Recent Conversations
```sql
SELECT * FROM conversations 
WHERE client_id = 'xxx' 
ORDER BY created_at DESC LIMIT 10;
```

### Count Documents per Tenant
```sql
SELECT client_id, COUNT(*) FROM knowledge_documents 
GROUP BY client_id;
```

### Check Tenant Isolation
```sql
-- Should return 0
SELECT COUNT(*) FROM conversations 
WHERE client_id != 'tenant-a' 
AND id IN (
    SELECT conversation_id FROM messages 
    WHERE conversation_id IN (
        SELECT id FROM conversations WHERE client_id = 'tenant-a'
    )
);
```

## Performance Optimization

### Cache Strategy
```python
from functools import lru_cache

# In-memory
@lru_cache(maxsize=100)
def get_settings(client_id: str):
    return fetch_from_db(client_id)

# Redis
async def get_conversation_context(conv_id: str):
    key = f"conv:{conv_id}:ctx"
    cached = await redis.get(key)
    if cached: return json.loads(cached)
    
    ctx = await fetch_from_db(conv_id)
    await redis.setex(key, 3600, json.dumps(ctx))
    return ctx
```

### Batch Operations
```python
# Bad: One at a time
for doc in documents:
    emb = await embedder.embed(doc.text)
    await vector_store.upsert(emb)

# Good: Batch
texts = [doc.text for doc in documents]
embeddings = await embedder.embed_batch(texts)
await vector_store.upsert_batch(embeddings)
```

### Connection Pooling
```python
from sqlalchemy.ext.asyncio import create_async_engine

engine = create_async_engine(
    DATABASE_URL,
    pool_size=20,
    max_overflow=10,
    pool_pre_ping=True,
    pool_recycle=3600
)
```

## Monitoring

### Structured Logging
```python
import structlog
logger = structlog.get_logger()

logger.info("message_processed",
    client_id=client_id,
    channel="whatsapp",
    intent="hours_inquiry",
    response_time_ms=125,
    tokens_used=450
)
```

### Metrics
```python
from prometheus_client import Counter, Histogram

messages_processed = Counter(
    'messages_total',
    'Messages processed',
    ['client_id', 'channel']
)

response_time = Histogram(
    'response_seconds',
    'Response time',
    ['client_id']
)

messages_processed.labels(client_id=cid, channel="whatsapp").inc()
response_time.labels(client_id=cid).observe(0.125)
```

### Health Check
```python
@app.get("/health")
async def health():
    return {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "checks": {
            "database": await check_db(),
            "redis": await check_redis(),
            "vector_db": await check_vector(),
            "llm": await check_llm()
        }
    }
```

## Error Handling

### LLM Timeout with Retry
```python
from tenacity import retry, wait_exponential, stop_after_attempt

@retry(
    wait=wait_exponential(multiplier=1, min=4, max=10),
    stop=stop_after_attempt(3)
)
async def call_llm(prompt: str):
    return await llm_client.generate(prompt)
```

### Connection Pool Issues
```python
# Always use context managers
async with db.session() as session:
    result = await session.execute(query)
    # Connection auto-returned to pool
```

## Deployment

### Pre-Deploy Checklist
- [ ] Tests passing
- [ ] Migrations ready
- [ ] Env vars configured
- [ ] SSL certs ready
- [ ] Backups enabled
- [ ] Monitoring setup
- [ ] Rate limits set

### Deploy Steps
```bash
# 1. Backup
pg_dump wafaa > backup_$(date +%Y%m%d).sql

# 2. Pull code
git pull origin main

# 3. Build
docker build -t wafaa-api:latest .

# 4. Migrate
docker run --rm --network wafaa \
  -e DATABASE_URL=$DB_URL \
  wafaa-api:latest alembic upgrade head

# 5. Deploy (zero-downtime)
docker service update \
  --image wafaa-api:latest \
  --update-parallelism 1 \
  --update-delay 10s \
  wafaa-api

# 6. Verify
curl https://api.wafaa.com/health
```

### Docker Compose
```yaml
# docker-compose.yml
services:
  api:
    build: .
    ports: ["8000:8000"]
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=redis://redis:6379
    depends_on: [postgres, redis]
  
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: wafaa
      POSTGRES_USER: wafaa
      POSTGRES_PASSWORD: ${DB_PASS}
    volumes: ["pg-data:/var/lib/postgresql/data"]
  
  redis:
    image: redis:7-alpine
    
volumes:
  pg-data:
```

## Quick Reference

### Common Commands
```bash
# Server
uvicorn app.main:app --reload --port 8000

# Migrations
alembic revision --autogenerate -m "msg"
alembic upgrade head

# Tests
pytest -v --cov=app

# Docker
docker-compose up -d
docker-compose logs -f api
```

### Code Snippets

**Get Tenant:**
```python
tenant_id = TenantContext.get_tenant()
```

**RAG Query:**
```python
rag = RAGEngine()
response = await rag.generate_response(query, client_id)
```

**Send WhatsApp:**
```python
await WhatsAppService.send_message(to, text, config)
```

### API Endpoints
```bash
# Auth
POST /api/v1/auth/login
POST /api/v1/auth/register

# Clients
POST /api/v1/clients
GET /api/v1/clients/{id}
PUT /api/v1/clients/{id}

# Knowledge
POST /api/v1/clients/{id}/knowledge/upload
GET /api/v1/clients/{id}/knowledge/documents

# Conversations
GET /api/v1/clients/{id}/conversations

# Webhooks
POST /webhook/whatsapp/{slug}
POST /webhook/instagram/{slug}
```

### Environment Variables
```bash
DATABASE_URL=postgresql+asyncpg://user:pass@host/db
REDIS_URL=redis://localhost:6379
VECTOR_DB_PROVIDER=pinecone
PINECONE_API_KEY=xxx
OPENAI_API_KEY=sk-xxx
META_APP_ID=xxx
JWT_SECRET_KEY=xxx
```

## Common Errors

**"No tenant context"**
→ Check middleware order, ensure tenant_id set

**"Vector search wrong tenant data"**
→ Always filter by namespace + client_id

**"Database pool exhausted"**
→ Increase pool_size or fix connection leaks

**"LLM timeout"**
→ Implement retry with exponential backoff

## Security Best Practices
- All endpoints require auth
- Tenant ID from token, not request
- Filter all queries by tenant_id
- Validate file uploads
- Rate limit per tenant
- Verify webhook signatures
- Use env vars for secrets
- Enable HTTPS
- Sanitize inputs
- Use ORM (prevent SQL injection)

---
v1.0 | 2026-02-06